########################################################################
########################################################################
#
#                   S M U L L ' S   T O D O   L I S T   
#                                     &   
#                   U N T R U E   C O N F E S S I O N S
#
#   Time-stamp: <01/05/17 19:26:02 smulloni> 
#   $Id: NOTES,v 1.1 2001/08/05 14:58:04 drew_csillag Exp $
#
########################################################################
########################################################################

CUMULATIVE CHECKLIST:

*** ARCHITECTURE ***

[ ] Need to check that mxDateTime is installed at configuration time

[X] Location needs to be localizable to a given port/service.  Thu Apr 26 18:14:37 2001:
    this notion clarified somewhat by notes of this date below.  The other items in
    this category are really all part of this.

[!] per-directory conf files (for what?)  Fri May  4 15:10:31 2001 off the table.  If
    we want to do this, we could write a simple Include directive, but now that scoping
    is part of the spec, this moves more into the multi-user/bastion/rexec development
    area, as well as the reworking of the config file format Forbidden Zone.

[X] the relationship of service to port: for http services, make it possible for more than one
    service to be mapped to the same port (via location or vhost techniques).

[X] the relationship between wire protocols (subclasses of Protocol) and jobs needs to be 
    clarified.  In particular, a way needs to be determined for protocols to determine what
    jobs to associate with a request.  

[!] the Configuration object is too complicated for what it accomplishes, and I don't like
    maintaining process state globally.  Forget that we have an implementation of SW and 
    thoroughly refactor the architecture with the additional design goal of supporting, optionally,
    a multi-threaded server.  Wed May  9 15:50:14 2001  We should indeed profile the config
    object carefully.  However, I am feeling more comfortable, not with the use of global
    objects per se, but with a fixed multi-process model.  Looking more closely at Zope
    again is quite interesting.  It has a lot going for it, but its threading creates a number
    of unexpected (for me) problems.  Security is more of an issue, and hence the whole 
    restricted PythonScript business.  Debugging affects the entire server, more or less
    ( it would be possible to do thread-specific debugging, but it would at the least 
    slow down everything -- we'll be able to do debugging on a live server without affecting 
    other processes directly.

*** REASONABLE STUFF ***

[ ] add File pseudo-directive to ConfigAdditives.

[ ] reuse HTTPConnection object in keepalive sessions.  Won't help with apache.

[ ] the next version of apache will need a new module, as the module API has changed dramatically.
    We'll need to support both apache 1.3 and 2.0.

[ ] export MMIntType from mmlib.mmint.

[ ] XML-RPC service, built on httpd. Fri Apr 20 12:38:18 2001: should not require httpd; should
    work just as well with apache.

[ ] ensure that if a log file is deleted, it will be regenerated, and that if the logger encounters a
    permissions problem, it deals with it gracefully (by creating another logfile, or logging to stderr).

[ ] find and fix atexit bug that crops up occasionally; make sure that swmgr works correctly.

[X] move aecgi into an apache service.

[ ] migrate MySQL service to the new MySQL module.  Generally check out the sql stuff.

[ ] debug levels and filename/line number tracing.

[ ] support multipart/byteranges encoding in httpd.

[ ] migrate superteam persona from AED.

[ ] install SW3 on roman's old box; get preexisting projects (women's channel, technet)
    running.  This implies writing aed_compat. Wed May  9 15:54:55 2001 SW3 is running,
    the old projects have not yet been ported.

[ ] for httpd: deal correctly  with multiple headers with the same header field (e.g., Accept).

[ ] httpd: complete go-through of rfc and Stephen Thomas' HTTP Essentials, adding/corrected along the way,
    and documentation of which features are implemented and which not.

[ ] clean up sw.conf; organize all configuration variables according to category and the service that 
    declares them;  comment every variable; format all variables names in the same style.

[ ] aed_compat: to the extent possible, add goodies from (AED's) templating.Init.py.

*** PIE IN THE SKY ZONE ***

[ ] make requestHandler permit writes not necessarily interleaved with requests, see note of date 
    Fri Apr 27 10:33:27 2001.

[ ] remote debugging; template debugging

[ ] content management (CVS, DAV)

[ ] par files for services & content

[ ] AddHandler support for mod_skunkweb

[ ] administrative interface

[ ] profile management (personalization), including implicit info gathering

[ ] optional restricted execution for conf files, templates.  

*** DONE ***

[X] httpd service

[X] debug should log the debug 'kind'.  Also, multiline logs shouldn't have the debug prefix
    on every line: wasteful.

[X] the log object should be moved into a pylib, but be configurable by SkunkWeb

[X] the new hook should admit of functions being added/called without a jobname, and
    hooks shouldn't be lazily initialized, but be created explicitly and owned by
    modules/objects close to their use.  hook methods can be called directly on them,
    instead of using static methods in the requestHandler.hooks module.  - partially
    done; still need a jobName for (because of the variable arguments list).  

[X] split up templating to use an AE component service that initializes the AE stuff.
    This can be used by remote, xmlrpc, too.

[X] remote components, preliminary

[X] revisit, rethink service registration: multiple keys per service; debug flags should be
    possible to set in the conf file.

[X] no-connection-response in request handler ("PreemptiveResponse")

[X] make sure that the new web service accomodates all hooks in old one (e.g., InitRequest)

[X] handle errors in remote components.

[X] in requestHandler: end document timeout after socket send and start new timeout for cleanup.

[X] add "interHookDict" to hook signatures in web_experimental.  Fri Apr 20 12:36:26 2001: modify
    Protocol to add a dictionary argument to all methods, and requestHandler should invoke it with
    the interHookDict, renamed to something like "connectionSessionEnvironmentDictionary", but
    one-tenth as long.

[X] make the hooks take glob keys to achieve cheap and dirty multiple inheritance. -- using fnmatch.
    functions keys are now globs, jobNames are what they match against.

[X] add code to templating_experimental to handle the client side of remote components.  -- actually,
    I added a remote_client service that supplements templating_experimental.

[X] simplify installation directory structure.

[X] modify requestHandler so it can support stateful protocols like FTP (the infamous interHookDict is
    really a protocol-level session object in any case, and this will dignify it).  A rather minor
    change, really; simply keep looping until there is reason not to. 

[X] Configuration.debugServices should either be renamed "initialDebugServices" or eliminated in some way.

[X] create aed_compat service that creates dummy objects (AED, REQUEST, RESPONSE, curl/loop tags 
    -- anything else?) to enable old scripts to be run and generally relieve us of backward compatibility 
    woes.  Also (Mon Apr 23 17:26:01 2001) ensure that message catalog paths in the AED 2.6 format
    (dot delimited, no extension) are also accepted in aed_compat.

[X] when code is sufficiently mature, rename the experimental services.  It is possible they could be 
    made somewhat more compact -- does web_experimental need to be a package, for instance?


[X] improve error handling in httpd and implement multipart encoding.  Error pages should be 
    templated in a somewhat more respectable fashion.  This is true for templating as well
    as httpd.

[X] implement keepalive for HTTP 1.0 and 1.1 in httpd.

[X] support "headers only" statuses, methods more robustly.

[X] put this list in some sort of order of importance/urgency, or integrate with an issue
    tracking system. Thu Apr 26 18:22:04 2001: reorganized list in a casual, half-assed way.

########################################################################

Tue Apr  3 10:59:31 2001

Well, I commemorated starting out this new file by deleting the entire Skunkweb project from my hard disk
in a failed attempt to remove *pyc files that I noticed were owned by root.  I'm not quite
sure how I did that, but luckily the number of changes that I made since my last checkin are
relatively small, and some of them are still in my Emacs buffers.  It is such a nice Spring day
that I'm not going to let it get to me.  I'll just let it get to some one else.  [goes beserk.]

########################################################################

Tue Apr  3 13:18:41 2001

First order of business: more remote component testing.  Then the changes to the hook code that
Drew suggested; next, separation of AE code into a component service. 

Tue Apr  3 15:37:55 2001

(I love my "shtick-timestamp" elisp function, but that's neither here nor anywhere else.)

More testing of remote calls on data components indicate that they work nicely, returning
all sorts of peculiar dictionaries, etc.  Errors are not handled well, at this point -- 
adding to todo list.  Modifying hooks now.

Tue Apr  3 23:58:23 2001

The hooks are now explicitly created.  They still work; I've verified that templating_experimental,
web_experimental, sessionHandler, requestHandler, and remote all are functioning as before.  Tomorrow
I need to consider marshalling errors from remote components; splitting of AE; debug problems.

I'm not thrilled about the fact that some services create actual web services, and some simply create
infrastructure for web services.  When LogObj is really moved out of Skunkweb, perhaps we can eliminate
services like requestHandler and reincarnate them as pylibs.  Or, on the other hand, we can eliminate 
the services directory and distinguish services from pylibs solely by whether they register with the 
application.  Generally speaking, I would prefer that there be as little code as possible that depends
on the dynamic, application-related aspects of Skunkweb.  

Delete garbage stuff from the CVS repository on bracknell....

########################################################################

Wed Apr  4 15:15:36 2001

So far so good -- remote component error handling works; ae component initialization has been moved
into a separate module, and hooks take glob keys.  

Wed Apr  4 16:11:59 2001

requestHandler's document timeout is now defined where it should be, in requestHandler's __init__.py.
The timeout is now reset after the response is set, and another timeout started for the cleanup hooks.

Next -- service registration and the debugging facility.  Not terribly exciting stuff, but it needs to
be straightened out.  Then I must choose the next service: httpd? xml-rpc?  Should xml-rpc run through
apache or through an httpd SkunkWeb service? Either?  

########################################################################

Thu Apr  5 09:51:12 2001

Service registration needs to be performed upon importation, but it must be possible
to refer to the service by name in sw.conf, so as to specify a debug flag.  A method 
like "setDebug(*services)", where services are a list of strings, would take care of
this requirement.  When services are reqistered, or when setDebug is called,
the list of services set for debugging is (re)compared with the list of 
services registered, and the debug flags are recalculated.  The only issue with
this is that services that have already been loaded will have old values of the
flags, and that's a major drawback.

Now, if we passed a string or other object instead of a boolean, we wouldn't 
have this problem.  But it would be more expensive.  I'll perform a benchmark
to see how much more, time-wise.

Thu Apr  5 10:43:21 2001

I did perform a benchmark, and found that using a boolean flag, in the best
case, took 80% of the time of using a string (the difference could often be
much less).  The difference was most noticeable when debugging was being turned
off (naturally).  Adding another global boolean flag to the debug statement
which was tested first was the best solution: if debugging is turned off,
globally, then the string is not tested.  

I would like to be able to modify debug information at runtime, but I think
that would be difficult to do with a forking server, unless I used shared
memory or some such trick (might be worth playing with this).  It is nice for
a sys admin to be able to turn up the gain on debugging on a live server.

Thu Apr  5 15:43:15 2001

Am considering wrapping the mm, the memory map library by Ralf Engelschall, in python,
with or without swig.  The API is rather small, especially if I stick with the 
highest-level API.  What the hell, I'll do it, as it may be useful later.

Thu Apr  5 17:19:51 2001

Wrapping the mm poses some problems.  A simple wrapper won't be very effective, as
sending Python a pointer to the shared memory space doesn't help anything unless
you also give Python methods to act on the pointer.  Instead, you should be able to
call a method whose value would be tied to the shared memory, e.g., 

	x = mm.shared("boo")

I have no idea how to do this with arbitrary Python objects in one go; what if 
they want to be created with pointers to ordinary memory?  But certain types could be
accomodated.  

I've derailed a bit today.  

########################################################################

Mon Apr  9 10:03:14 2001

Apparently I forgot to write of my little triumph (getting an extension type, for memory 
mapped values, to work) on Friday.  It is not usable as is, for the following reasons:
	1. I need to be able to store more types.  It would make sense to write a generic
	   container, but I need to make sure that no pointers outside of the shared memory
           space are added to it, at least post fork, and I need to manage its memory.  I will
	   look at how Python itself manages its dictionaries to determine whether I can safely
           use a python container within the shared memory, and trust it to stay there.  Probably 
	   not (it must realloc under some conditions).
        2. I wrote the mmint using mm's global allocation api.  I should explicitly create and manage
           the memory pools, so I can use more than one.
        3. I am not destroying the memory pool -- I need to find out whether there are any resources 
           that won't clean up after themselves that I should release (a file, for instance).  If so,
	   I'll need to install some sort of handler to detect exit.

My idea is to put as much of the config data as possible in shared memory.  Is this important or
particularly valuable?  No.

In other news: my other priorities.  This detour got started because I wanted to rewrite the logging class
and the service registry.  Take care of that first.  The service registry owns the debug flags; it could
use the memory mapped ints.  The configuration files should specify a list of services to debug, and the
debug flags will be set automatically.

Mon Apr  9 15:36:55 2001

I've improved the memory mapped int and integrated it into the logging framework, which I am currently
reworking.  In order to test it and various other changes I've made along the way, I will need to do
a fresh install (some of the changes are to bootloader.py.in and swpython.py.in).  I will probably
not perform that install until tomorrow morning.

The debugFlag class is in Logger, not a configuration variable.  The configuration variable that 
corresponds to it is debugServices, which should be a list of strings.

I need to export the MMInt type in mmint.c, and possibly install an atexit handler, either in python
or at a lower level, via signal handling, in C.

Mon Apr  9 18:44:59 2001

Decide where to put the debugRegisteredServices() call.

########################################################################

Tue Apr 10 10:05:22 2001

I believe I do need to clean up after the shared memory, if my reading of Understanding the Linux Kernel
is accurate; shared memory will not be cleaned up after the processes using it exit.  So where do I put 
this cleanup?  An atexit handler will get called for every process, which won't work. [Tue Apr 10 11:09:51 2001]
Determined, using ipcs, that the memory segments do get cleaned up by mm, although I haven't found the 
relevant lines in the mm source code that achieve that.

OK -- on to bigger and better things.  I would like to simplify the directory structure of the skunk
installation.  At the moment, pylibs, SkunkWeb, and Services are all contained under "[prefix]/lib/skunk".  
I'm moving them directly under lib: lib/pylibs, lib/SkunkWeb, lib/Services.  The var directory also has too 
verbose a directory structure -- var/log should be good enough.  I'd be tempted to put lib/skunk/util some 
levels up, in util.

The sw.conf file should come, by default, verbosely commented, with default values (commented out) and
an explanation of each setting for every bundled service.  When an installation format for services is
determined (using pars), it might include a configuration section which will be appended to sw.conf.

Tue Apr 10 18:43:12 2001

Well, after considerable reorganization, I've got it to work again, but it is quite unstable.  I'm checking in
for synchronization purposes, but there are no doubt numerous bugs to be tracked down.

########################################################################

Wed Apr 11 12:45:34 2001

Keeping a list of debugServices in the Configuration object won't work very well, since different processes
will have different values, unless they too are memory mapped, which seems unnecessary.  Instead, the configuration
file can call debugRegisteredServices() directly. 

Wed Apr 11 16:20:50 2001

Well, the above isn't what I've done.  I may del debugServices from Configuration after I've used it, but
at present I'm reading it to get an initial value, and computing the current value from the shared flag in ServiceRegistry.

The MMInt was segfaulting in the coerce method.  With advice from Drew, I reexamined the reference counting, and
by Py_INCREFing the second parameter I made the problem go away -- good feeling.

Most of the crashes have been fixed, but by no means all -- I still have a rather chaotic feeling about the current
state of the code.  A few more hours of tidying up, and I can move to the next problem.  The general problem of
putting configuration data in shared memory is still pending, but I never meant to spend several days on this; 
having demonstrated to myself that the concept is sound, I can leave it at that until it is really necessary
(when I write an administrative interface).  

Wed Apr 11 16:51:29 2001

Next steps -- an httpd service, serving web requests directly from SkunkWeb.  This needs to be designed in such
fashion that extending it to support DAV and XML-RPC will not be a problem.

To my surprise, I seem to have cleaned up fairly well after my code mess.  It is working quite well.  

I should probably add a test directory to cvs and use it for small test programs and templates.  

########################################################################

Thu Apr 12 09:44:55 2001

I'm thinking about blowing away my Windows partition and installing a Reiser partition there, moving crucial files 
from the other partition into it, then blowing away the ext2 partition and resizing the reiser to cover the whole disk.
I'll see how my LFS machine works out, and whether I want to install LFS, or go with RedHat or Debian.  

Today: templating really needs to support remote component calls directly.  The component URI can determine what
protocol to use: local component call, remote call, xml-rpc call, etc.  If I rewrite the component tag to accept
pluggable component protocol implementations, new services can supply additional functionality: xmlrpc_client,
remote_client, corba_client, etc.  When this is done, the httpd service beckons.

SkunkDAV bug -- empty strings are not recognized by the syntax tokenizer for Python.  Also, the STML tokenizer 
needs to be expanded to cope with new tags (the log tags, for instance) in SW3.

Check to see whether the first argument of coerce methods in Python/C api need to be PyINCREFed.  Also, the
coerce method raises a SystemError for cases like "mint & None" -- I need to set a TypeError exception in that case.


possible installation directory structure:
@sw@/lib:
	sitelibs/ # user-specific -- default location -- or should this be in share?
	services/ # contains SkunkWeb package -- manditory location
	pylibs/   # general purpose -- manditory location
@sw@/share:
	docroot/  # default location
	errorDocument.html # default error document
	cache/    # cache -- should probably be configurable (is it?)
@sw@/bin:
	various executables: swmgr, swpython
@sw@/util:
	scripts for maintenance, debugging, etc.
@sw@/etc:
	configuration files. (at present only two, but there could be more)
@sw@/var:
	log/     # log files.

I'll have to take a look at pars and see how that fits in.

Thu Apr 12 13:55:32 2001

Debug flags in AE package need to be in sync with the ServiceRegistry.  The
extra config object that is uses is pointless, also; replace it with a ConfigLoader.Config
throughout.

Component tags now process swrc:// urls, and AE.Component now can take pluggable component handlers.

Thu Apr 12 23:24:34 2001

Removed the "file://" protocol from AE.Component, which I added in an oxygen- or carbohydrate-deprived state
this afternoon.	

Fri Apr 13 14:20:16 2001

Sketching out an HTTPProtocol implementation of requestHandler.protocol.Protocol, as a basis for a web server.

Issues: 
	1. what exactly does apache add to the equation?  Do I need to munge the response headers?  What is the
	   best way of obtaining the necessary environment variables?  To determine this, I'll write a tracing
	   program similar to my Java LoggingProxyServer to monitor traffic, but I think I'll do it in C this time
   	   (for practice), perhaps with a GTK front end (GTail?).  There must be a way for me to intercept the traffic
	   without having to direct the request to a different port -- sniff it instead. 
	2. I would like to implement keep-alive, not just for HTTP, but generally, for stateful protocols; in the
           case of keep-alive, it is the content of the client request, among other things, that will determine whether
	   the requestHandler session is terminated.  A session might time out, also; I wouldn't handle that with an
	   alarm (one is already installed for DocumentTimeout) but would check the cumulative length once per cycle
	   and end the session post-request if that were timely. 
        3. The http server could support a variety of jobs -- at least one per http method.  How do I indicate that?
           By globbing? */web/http/*/get/ ?  What web job the server should ask for for a given request also needs
           to be configurable -- for GET, for instance, one might want a templating job on one port or in one location,
           and a simple file dump somewhere else.

I think I may end up working on mod_skunkweb and the http server concurrently.  Apache's example would be helpful.

########################################################################

Mon Apr 16 13:51:37 2001

Drew pointed out that a log stamp on every line of a multiline trace can be useful for grepping the file.   
I've made it a configurable option, defaulting to Drew's preference.

Restarting the server caused a crash in SkunkWeb.Server.py, as the Configuration module was deleted and 
then referenced.  Fixed.

Mon Apr 16 17:36:04 2001

Work on http going slowly -- I have some background work to do.

########################################################################

Tue Apr 17 10:44:34 2001

Last night, more experimentation with the socket API.  Java gave me too high-level a take on it, without non-blocking
i/o, without signals, largely without socket options.  My current issue is the correct way to read an HTTP request.  

Tue Apr 17 14:07:26 2001

Still the same issue.  The question is when I know that I'm done reading.  There are four cases of which I am presently
familiar, two of which I know next to nothing about.  1.  Headers, and no body.  That's easy to do -- read until a blank 
line is present (two CRLF pairs, to be picky, but I notice that Medusa doesn't require the client line separators to be
CRLF).  2. Headers, one of which is a content-length header, and a message body.  That's also really easy -- read that much
past the headers (if the length is acceptable).  3. "Chunked" encoding.   4. Multipart encoding (file upload). 

Then there are anomalous cases -- posts without content-lengths, etc.  I believe these may safely be disallowed.

Medusa (and its derived standard Python module asynchat) handles this by delegating the read to an object with
the responsibility of collecting the request, with two abstract methods, "collect_incoming_data" and "found_terminator".

I'm slogging my way through rfc 2068.  The socket programming necessary for http seems to be quite simple; it is the
odd, dusty corners of the protocol that require assimilation.

########################################################################

Wed Apr 18 12:19:02 2001

I wrote various mini-proxy servers in Python, forking, not forking, forking twice and using a pair of pipes,
using SocketServer.  The SocketServer proxy works well enough to use for testing, although not any better
than my Java version.

In any case, I'll add a special debug capability to the webserver that logs the complete text of ALL traffic.

marshalRequest will read only the first line of the request, and then attempt to find a method handler.
If it does, the method handler's marshalRequest method will be called.   Then the request enters
the usual pipeline.  The method handler probably will need to install request handler hooks, etc., depending
on what it is doing.  If no handler can be found, an exception handler should take over and return a 405 
(Method Not Allowed).  The PreemptiveResponse mechanism would be appropriate here.

The scanty preliminary code I put in web_experimental is coming out and going into its own service.

Wed Apr 18 16:37:39 2001

various questions coming up that require going through RFC 2068 carefully.  Rather than searching for each
separately, I'll collect them and periodically reread it until I feel like throwing up.

add more error handling for socket reads.

The aecgi protocol should probably be moved into a separate apache service.  At the moment, templating_experimental
assumes that it is required.

Still filling in the underpinnings for httpd, creating the environment, parsing the url, etc.  In another day, 
let's see the mechanism work for a GET and a HEAD!  I'm going to keep on truckin' until we have DeltaV!!

@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
CUMULATIVE LIST OF HTTP PROTOCOL QUESTIONS

[X] should the http version reported on the status line be the version of the server or of the client?  I presume
    that it should be the latest protocol supported by both, but need to confirm that.  -- Yup.
[X] can a request legally have multiple request headers of the same name, and what do I do with them? --
    It is legal (for some headers), and I resolve the headers into a comma-separated list.

@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@

########################################################################

Thu Apr 19 11:38:48 2001

Enhanced my bash script for finding long lines using getopts.  Now I suppose I should fix the long lines (sigh).

Thu Apr 19 16:19:32 2001

Today's work has clarified for me that the web server's method handler methods do not and should not actually
handle the request service (except for preemptive responses and error messages).  That is a matter for services
that define jobs -- templating, webdav, etc.  How best to manage jobs so multiple jobs can function on one port
is still an outstanding issue, but I believe a fairly isolated one.

Writing a simple webserver is one thing, and writing a fully compliant and efficient HTTP/1.1 one is another.
What I am doing now is a good exercise, but whether it will amount to more than that is rather doubtful.  Still,
it will be interesting to compare its performance against SkunkWeb with apache and mod_skunkweb, and it is a nice
test of the extensibility of the SkunkWeb framework.

The distinction between services that create jobs and services that do not is quite important, and in a type-safe 
language I would find various ways of underlining it.  As it is, a "service" is just a package or module with
dependencies on the SkunkWeb package.

I should find, or write, a battery of tests that I can use against httpd.  Apache must have a test suite. Hmmm. 
I found a project that used to live at the ill-fated sourcexchange; looks a tad unpleasant.  A python test suite
would be super.

Since HTTP methods are not being blocked by mod_skunkweb, it is up to apache to block them or not (the 
httpd.conf.stub should be modified to demonstrate this).  Similarly, the httpd service will block a request
if its method is not installed, because we need to know the method to parse the request.  However, later request
handlers do not see the request method in the jobname; if different actions are to be taken for different methods
(one would hope so!) then that is up to the handlers/components/etc.

Thu Apr 19 17:38:15 2001

Pretty close to an initial prototype, but I have to go home and can't test it yet.  I haven't implemented 
multipart encoding yet, which I will need.  I need to improve the error handling and fill in some gaps, like
actually adding handlers, deciding where the controlling code should go, what configuration variables are needed,
etc.  Then we should be able to run SkunkWeb standalone, sans apache.

Fri Apr 20 00:24:49 2001

Start writing test cases of the following form: web client hits server with a given request 
and receives a response which it can compare with some expectation.  Particular server side
components will have to be part of the tests, but I can test httpd against apache to eliminate
them as sources of error.

Fri Apr 20 12:27:44 2001

Today's sole goal is to get the webserver running to a minimal degree.

Get communications yesterday and today about SkunkDAV from users.  Several bug reports/feature requests from 
Ben Hutchison, which I added to the tracking system at sourceforge.

I believe that the interHookDict, or connectionSessionEnvironment, or whatever it should be called, is 
probably necessary for all requestHandler hooks/methods, including the protocol methods.  For instance, 
in http, if a server error occurs and a 500 is returned to the client with an error page, what http
version should be used?  Depends on the whether a version was specified by the client request, but 
Protocol.marshalException(exc_text) doesn't know anything about that.  I could use the protocol object
itself as a container, but it would then need to be cleaned out every request, and the data stored in it
wouldn't be available to other hooks.  So the connectSessionThing should be given pride of place.

Fri Apr 20 17:40:45 2001

I have a very rough webserver now running correctly with GET; I haven't yet tested POST, and certainly not
chunked encoding.  I am currently pulling the Status line out of the request header and duplicating it in
the request line, but not removing the Status header, which perhaps I should do.  I will check against
apache's behavior.

Essential work on httpd:

* test against apache -- compare treatment of status header, transfer encodings, errors.
* more method implementations.  Onwards to DAV and DeltaV.
* configuration for aecgi and httpd is very awkward and makes very little sense.  A 
  nested data structure, like XML, would make more sense -- one per port, most likely.

########################################################################

Sun Apr 22 14:41:54 2001

started to convert to using sessionDict.  

########################################################################

Mon Apr 23 00:08:30 2001

converted all services to using sessionDict; updated several old services to the new framework.
Basic auth needs to have its two hooks combined into one (the division was an artifact of the
previous architecture).  Also, it is essential that basic auth work with location directives, which
I don't think it does at present.

I came across code in medusa, or maybe it was Zope's ZServer, that pulls the status header out of 
a response, puts it in the status line, and deletes the status header.  So I guess that's kosher CGI;
I'm doing the same thing.  Unfortunately, this means taking the response string that the HTTPConnection
object has already created and performing surgery on it; I don't see a good way to get at the header 
dictionary at an earlier point, given the current design.  The parsing and copying of headers isn't so
bad; what concerns me is that the entire response string is being copied (it would be nice if Python 
did a sort of copy-on-write thing when you do someString[n:], but I don't suppose it does).

I'm checking my provisional code and will test much of it (httpd, basic auth, regression) tomorrow.

Mon Apr 23 12:01:56 2001

I decided against combining the basic auth hooks, because of location-specific config overlay.  I put
get the remote_user/pass data before the overlay and check authorization afterwards.

I've also added a KeepAliveTimeout, implemented, at Drew's suggestion, with select.  Drew also proposed
that the debug system could be enriched by optionally adding the filename/lineno to the trace.  Debug
levels would also be velly velly nice.  Adding to todo list.  

Some environmental variables need to be set inside the CGI environment, because Apache or any other
httpd has no way of determining them.  Authorization is one case.  Also, PATH_INFO and PATH_TRANSLATED.
I will have to scout around looking for the right spot to determine these and stick them in (right after
the actual component has been found).  I don't know if extra path info will even work with the current 
setup, much less post-semicolon params (although I'd like to make them do so, and use them for sessionIds
for cookie-less clients).

Mon Apr 23 13:10:37 2001

SCRIPT_NAME also needs to be checked and defined after the component has been identified.

Mon Apr 23 13:52:14 2001

POST works fine with form data; HEAD probably does not work, and multipart form data is still out
there.

Mon Apr 23 15:55:02 2001

Added some more comments to sw.conf.in and renamed Configuration.debugServices to initialDebugServices.

I lost an entry here earlier, in which I commented that multipart form data was not out there; I was out
there.  Multipart form data works just fine; multipart-byteranges, however, is currently not supported, 
although I am adding it as a todo.

Just noticed that "SkunkWebVersion" is a Configuration variable, meaning that the variable I added to
SkunkWeb gotta go.  Done.

Mon Apr 23 18:52:18 2001

Added some support, maybe enough, for keep-alive.

########################################################################

Tue Apr 24 14:16:25 2001

Being in a brain-dead state, I've started to reconfigure roman's box to run SkunkWeb/Oracle, so I don't
need to install Oracle on my laptop. CHECKLIST:  upgrade to RH 7.0, upgrade kernel, install: Python 2.1, 
xemacs, sudo, mm, SkunkWeb ....  Once networking is up and running on my lfs box I'll do the same there.

For lack of a better idea, will start on an aed_compat service.  Starting it, I see the need to learn more
about the interface the previous version presents.  The best way to learn this is to port the superteam
personality, so that's the next step.

########################################################################

Wed Apr 25 16:38:04 2001

aed_compat seems to work, although it probably needs to be expanded.  More testing on actual aed code is 
in order.  I have renamed the web and templating services.  Attempts to upgrade Roman's box without 
entirely blowing away the previous installation have resulted in an unbootable entity.

Wed Apr 25 16:56:25 2001

I'm reformatting Roman's box("rufus").  If it still doesn't boot, it can go and ROYALLY FUCK ITSELF, however
royals do that.

[deep breath]  OK.  Onwards.  Setting up a server is a chance to work on installation.  The previous skunk
installation script was a little too chatty for my taste, but I do want to make sure that installation has no kinks.

########################################################################

Thu Apr 26 15:04:10 2001

I've done some aed_compat testing -- so far so good.  Fixed a couple of bugs in AE.MsgCatalog.py.  I've
added a DefaultLanguage (why did I capitalize it? should rectify that) to Configuration.

Do a little thinking about locations and vhosts.  I think a more powerful generalization is in order.

Thu Apr 26 16:00:14 2001

SkunkWeb has several categories that are a little hard to keep focussed.  The terminology I am introducing
below is for my own convenience, for the nonce only.

1. A pyservice is a python package or module that provides a particular unit of functionality.  It may or
   may not provide a netservice; many pyservices provide the framework for other pyservices, modify
   the behavior of other pyservices, etc.

2. A netservice is a concrete service provided to clients by the server, speaking across a TCP or UNIX
   socket in some way.  Many netservices can be supported simultaneously by the same server, and, to 
   some extent, can be configured separately.  The limitations of the latter are much in need of being addressed.
   Netservices are the fundamental units of functionality that SkunkWeb, and its pyservices, provide.
   A netservice is at present always in a 1 to 1 relationship with a port or socket, although that may
   change (one port may support more than one netservice).

3. One category of netservice is one that supports operations for HTTP (whether or not the netservice itself
   speaks HTTP directly, or speaks through another protocol).  The web pyservice provides the principal support
   for this; the templating pyservice provides a concrete implementation (and can be configured to provide
   a concrete netservice, with a built-in webserver or via an apache module).  Web netservices (webservices)
   always take a a URL parameter; that consistent parameter is, in effect, an additional dimension in netservice space.  
   
4. To a limited degree, we make it possible for the configuration of a webservice to fluctuate depending on 
   the value of the URL (by means of the Location pseudo-directive).  However, at present the Location pseudo-directive
   affects all webservices, not only selected ones.  A WebDAV server on port 8080, an XML-RPC server on port 7777,
   and an apache app-server on port 9888 would all be influenced equally by any Location directive, which is clearly
   not desirable.  It should be possible to treat separate netservices as separate entities, make rules that
   affect all netservices of a particular type, or that affect all of them.  Optional parameters to add to Location
   would then be port and netservice (except that at present there is no typing of netservices!  there should be),
   and if typing of netservices is too awkward, we could always force the configurer to simply list all relevant
   services (in the current model, there can't be more than a handful, although that model may change). This would 
   solve most practical issues, but is still a weak generalization.  

5. The generalization above misses an opportunity: to treat a webservice as a new type of netservice, a metaservice 
   or multiservice, so that on the basis of URL entirely different netservices might be offered.  This would make 
   netservice definition easier, too, because there would be less constraint on their domain of responsibility.  How
   do we do this?

6. Another category is that of "job".  I introduced jobs in order to use jobnames as labels on data as they
   pass through processing hooks, so the correct hooks could be applied to them.  The jobname determines the set of
   tasks that are performed given the initial input.

7. Another category: "vhost".  A vhost is implemented in SW simply as a URL-rewriting rule (and, at
   present, as a very rigid one). Vhosts should also be separately configurable.  How should Location and vhost work
   together?  In any case, vhost and Location are both strictly webservice features; a metaservice should be conceived
   more abstractly, perhaps requiring a parameter like a URL, but not necessarily a real URL, or HTTP environmental
   variables (such HTTP_HOST, upon which vhost depends).

8. For a metaservice to work, it needs to speak a consistent transport protocol, so the request can be marshalled
   and it find its fulcrum parameter(s).  Then, on the basis of the those parameters, it would determine the jobname
   for the request.  This is what I've been missing (although I had a note to myself that's been around for weeks in
   this todo list, asking myself to clarify the relationship between wire protocols and jobs).  The key is to specify
   the jobname in a location block (or whatever generalization of location I come up with).  requestHandler.protocol's
   Protocol class is, in effect, the metaservice class.  What it lacks is a decent way to associate jobs with protocols;
   I thought of adding a getJob method, but what parameters would it take?  When would it get called?  There may still
   be issues here -- do I need a jobname at any point before the request is fully marshalled? If so, can that jobname
   be statically associated with the protocol implementation?

9. How to extend location?  First step -- remain in the web problem domain, flesh it out, and then generalize further.
   Locations currently accept configuration variable kwargs and a pattern which is matched against the beginning of
   a URL, no globbing, no regex.  I'd like to be able to do things rewrite "(.*)/manage" into "/manage/\1", or make 
   some rule that applies to "/smullyan/.*/\.jpg".  If regular expressions are allowed, they need to be stated in
   order, as if you were writing a lexer.  

   Let's say you want to have certain directories use the (non-existent) management service.  A Location directive 
   like this turns it on (in pseudo-code, I have no idea what this should look like yet):

     # first, there is a directory underneath docs/manage/ that I want to have default properties
     Location docs/manage
	pass # just make it exempt from the following
     End Location

     # then, turn on basic auth everywhere
     Location .*/manage/.* # applies to everything below a manage directory on all webservice ports
        auth on
        authfile=private/management.db
     End Location

     # finally, in files in the management directory, but not in sub directories,
     # make it a management job
     Location .*/manage/[^/]*  (types=['httpd']): # for httpd netservices on whatever ports they occupy
        job=MANAGEMENT_JOB
        language=eng
        # etc.
     End Location
    

   Some management directories have subdirectories which may require that additional configuration be overlaid;
   some others may wish to override the configuration of their parent directories completely, with prejudice,
   without having to inherit their parent's  location-specific configuration.  The above may be confused,
   in particular about how subdirectories are exempted from acquiring the traits of their parents, but we'll
   figure it out.  

   Now, I'm not a big fan of Zope's acquisition trick (should be called "guilt by association")  but it could be 
   implemented this way.  If I wanted to associate an arbitrary python object with a directory and have objects
   underneath acquire it, they could get it this way, by putting it in the config overlay.  Really it is up to
   the developers how confusing they want things to be.  I don't want to implement acquisition so as to give 
   people a new way of handling namespaces -- I want to manipulate the configuration namespace so that many
   services can be offered in one URL hierarchy, from the user point of view, and one protocol can delegate work
   to many different service engines, from an architectural point of view.  Acquisition is really just a side effect,
   although an important one.  By making acquisition work through regular expressions, it becomes arbitrarily powerful,
   and potentially dangerous.  You don't want each develop defining his/her own acquisition rules, thereby affecting
   other people's work ("how did a picture of Bill Cosby getting naked with Moshe Dyan wind up in Henny Youngman's 
   obituary?!!")  Well, you just don't use this facility for that purpose.  As it is, you could use Location that
   way, by sticking weird objects, "html_footer", say, inside of Configuration.  At the moment, there is no way to 
   prevent that; the Configuration object can be munged to an arbitary degree from just about anywhere in the application
   or the user code.  
 
   We really have to think about whether this "side-effect" should be left as a big No-No, or whether we should
   embrace it as Zope did.  The solution to acquisition abuse may lie in some of rexec/Bastion technique for
   distinguishing the degree of privilege different users have to do fucked-up things.  I personally crave the highest
   possible degree of latitude in that area.
   
More musing is in order, but some relatively clear-cut steps can be taken.  Protocol might as well have a getJob()
method, for one; then write code to get the Configuration object and its weirdness involved in mucking with jobname
dynamically.

########################################################################

Fri Apr 27 10:24:44 2001

At the moment, the main restriction I see in the requestHandler is that a socket send and a socket read always exist
in pairs, and the requestHandler enforces that the read be actual by doing a select after the write before it cycles
around.  This doesn't sit very nicely with the HTTP Continue header, for instance.  I suppose it works fine, within
buffering limits, for request pipelining, as the next pipelined request will sit in the read buffer until the server
gets around to reading it.  I think I should permit more flexible communications, not always tennis-style back and forth;
this could be done by making the socket available to other stages in the request handling cycle, or by permitting 
the select between cycles to be skipped if keepAliveTimeout returns a certain value.  I don't need this right away, but
we should be aware of it as an issue -- adding to "pie in the sky" todo list.

The acquisition issue could be handled by writing an acquisition service that would affect a target namespace (e.g., in 
templating, _h).  Acquisition rules might be constrained to only apply to subdirectories.  Then any template in dir1/foo
could be made to inherit any variables explicitly entered into the acquisition pool for dir1, but not vice versa.

When a server is added, some sort of record needs to be kept in a data structure, so Location can refer to it.

Protocol is already returning the jobname in marshal request (first item of returned 2-tuple).  

Fri Apr 27 13:32:51 2001

Various interruptions.  In order to do what I am thinking about, the request processing gauntlet has to be changed.
First of all, data from the request needs to be evaluated earlier by the protocol object, during marshalRequest, 
so it can use it to dynamically determine the jobname.  That being the case, why not, in the case of webservices,
create the Connection right away?  Otherwise the work that the connection does, creating the url, etc., is done twice.
In addition, postponing the config overlay will not be possible, if the determining the jobname requires the overlay; 
it will need to be called inside of marshalRequest. Or, rather than returning a 2-tuple, perhaps marshalRequest should 
return just the requestData, and the protocol object should return the jobName in a separate method.  Then processRequest
can get the requestData, perform the overlay, and then ask the protocol object for the jobName.

I'm also making the assumption here that the acquisition, or localization, or whatever you want to call it, should
take place inside, or modify, the Configuration object.  Obviously that means that the requestHandler is profoundly
non-reentrant, but that has always been the assumption anyway.  It just means we'll be one step farther away from
being able to support threads.  If, on the other hand, the Configuration object was not global, but existed in the
sessionDict, we'd be considerably safer (but vast amounts of code would have to change to accomodate it).  Generally,
I would prefer to write thread-safe code even if we would bet our savings that the code does not need 
and will never need to be thread-safe; but that seems like too massive a conversion.  TO BE CONSIDERED.

How is the protocol (or rather the JobSpecifier) supposed to determine the job from the path?  OK, a config overlay
occurs.  One possibility is that a config variable, "jobName", is set for the path/port-id (port itself shouldn't be
used as a key, as the port number might be changed, and then the same magic number would need to be adjusted all over 
the place.  Rather, make the actual port number an attribute of a port-id.  Is this the same thing as host?  No; define
the difference ***).  Another possibility is that the jobName is determined dynamically according to: 1. request data;
2. session data; and 3. (localized) config data.  The first possibility is a special (vacuous) case of the latter.
But what are other examples of how it might do that?

A less drastic overhaul might be possible if the jobname were to change after the overlay.  The jobname prior to that 
point is the default jobname, then after the overlay, the jobname is (optionally) updated.  This imposes some limitations.
However, there is already a limitation in the current design, in that a socket opened with a given service cannot
switch wire protocols.  It should be possible; if SW speaks lang1 and lang2, and determines from speaking with me in
lang1 that I also speak lang2, why can't we simply decide to switch into lang2?  However, that feature is not terribly
important, since lang2 is presumably available on another port.  (On the other hand, a perennial problem with distributed 
computing is dealing with firewalls.  RMI in Java suffered from this.  What if you could open an IIOP communication in 
HTTP on port 80, get the socket, and rather than tunnelling,  simply switch protocols?)

All this may seem like overkill, but I am envisioning SkunkWeb supported a wide range of protocols: HTTP, proprietary
inter-app stuff like aecgi, IIOP, HTTP extensions like DAV, XML-RPC and SOAP, P2P protocols like Napster, Freenet,
Gnutella.  Most of these are only a couple of years old.  AED is now two years old itself.  The next two years should
introduce new protocols that we'll want to support, and we shouldn't want to merely support them; we should find ways
to use them together that increases their power.

Fri Apr 27 16:33:22 2001

This is all mangled up.  Starting over.

For ALL (request-handling) netservices (it would still be possible to write services that don't use requestHandler):

   I want a directive which enables me to set configuration data and determine the jobname on the basis of some value(s) 
   derived from the request and on the netservice id.

For webservices in particular:
   I want a special case of the above directive, in which the relevant request datum is the uri or path. 

When multiple netservices are run, there is no reason why their basic server configuration should be the same.
An apache service might need 15 processes, and a development-only httpd service only need 3, etc.  Netservice ids 
should make this feasible as well. Thu May  3 11:39:56 2001 WRONG.

My attempts to code this so far have not succeeded, because I'm not yet clear what the proper extent of the changes
I make should be.  

########################################################################

Mon Apr 30 11:57:51 2001

A couple of mistakes in the above notes that dawned on me later.  
  1.  protocol switching isn't terribly useful as an alternative to http tunnelling, as proxies wouldn't be 
      able to handle it.  That doesn't mean it would never be useful, but neither would it solve any current
      problem.
  2. Something else that will occur to me later.... Thu May  3 11:34:44 2001: Somewhere i wrote about specifying 
     different numbers of server processes per port.  That ain't how it works, so retract that idea.

Scope directive: from the user POV:

Scope(	scopedArgName=scopedArgRegex, 
	netservices=[netserviceID1, ...], 
	configTarget=obj, # defaults to SkunkWeb.Configuration
	**overlayKwargs)

When an object is scoped, a reference to it is stored in a series of scoped objects, and at the end of a request, it
is descoped, if it supports descoping.

Rather than insisting that all services provide scoping, and struggling to find a way to integrate it directly into
requestHandler, could I write scoping code that other services can integrate in the way that makes sense for them?

Mon Apr 30 15:51:48 2001

The current ConfigOverlay business was greatly facilitated because the overlays could be ordered, because the comparison
operation was so simple.  A more powerful comparison operation cannot be ordered so simply.  Their precedence needs to be 
stipulated by the user.  I don't see a nice way of handling this.  The difficulty of doing this means, perhaps, that
there are other better ways of achieving the dynamic effects that scoping could be used for.  On the other hand, 
abstraction can be maintained, if I simply require that the match keys be sortable. 

Mon Apr 30 17:35:57 2001

My epic struggle with my own brain-deadedness of the last few days has yielded fairly slim pickings, the beginnings of a
Scopeable module which may or may not be able to replace/supplement/undermine the Config object.  I haven't written
any new code, simply reworked what was there in slightly different form.

########################################################################

Tue May  1 16:34:44 2001

The scope module appears to work correctly.  Integrating in a hackish fashion into SW was very simple; at the moment I have
it simply replicating the previous behavior.

Tue May  1 17:50:30 2001

The next step along this path is to determine the appropriate time for scoping to occur.  For webservices, it does make 
sense that it occur AFTER the connection object has been created, as is already the case.  Perhaps it needs to be up
to each service family to manage that hook itself.  What other parameter would it make sense for webservices to scope on?
The host header -- name based virtual hosts.  I just implemented it by accident -- whoah.  I've cleaned it up a little and 
verified that it does get called as desired;  later I'll test that does all the right things, can support different doc roots, etc.

Tue May  1 23:20:47 2001

Obvious problem with above occurred to while boarded subway train -- while it is possible to scope various different 
parameters, it currently isn't easy to scope them conditionally upon each other (requires writing a scope matcher that 
checks for two conditions).  What is needed is the ability to nest scope rules, a la apache's config files, where a
virtual host directive can contain various location directives, etc., that don't affect other virtual hosts. At present,
all scope directives are orthogonal relative to each other.  One would like to call overlay *once* only for a given 
scope value, pass it the high level matcher, and let the nested matchers magical-like pull out the particular parameters
they are supposed to match.  That isn't without its complications.  That means that something that looks very much like
a namespace is being matched, a namespace from which various values are being pulled, possibly from within the namespaces of
contained objects; the matcher must be competent to perform this series of extractions.

Wed May  2 00:28:23 2001

Netservice ids are still needed, and making location directives include them in the match is another case where we need
to match more than one property at once.  If scoping a Scopeable is done in one operation, in which it is passed all the
relevant values, life would be easier.  Either that, or the scopeable has to constantly rescope itself: when scope data is 
added, the scopeable trims itself, and tests all the matches over again.  Better, probably, to collect all the data first
and send it over all at once.

Per directory conf files are trivial when this is done; the admin simply allows certain other files to be included (perhaps
in a restrictive syntax which would need to be created and managed).

########################################################################

Wed May  2 11:17:20 2001

Reworking scope.py to handle nested scope directives.  I am thinking of putting the overlays inside the
matcher, rather than associating them in a dictionary; then all we need for each top-level scope param is a 
list of matchers.  Those matchers can have children.  Then we have an XML-like structure:

<overlays>
<param name="param1">
   <matcher matchobj="test/foo" type="scope.StrictMatcher">
	<children>
		<param name="param2">
		    <matcher matchobj="limpopo fudge" type="scope.StrictMatcher"/>
                </param>
        </children>
   </matcher>
</param>
</overlays>

When a scope is performed, the how do the nested scope objects get invoked?  We need a "matchee" structure.

Wed May  2 13:57:34 2001

Progress made.  I've created four directives: Scope, Port, Host, and Location.  Scope does nothing except 
actually add scope matchers to Configuration.  Port and Host permit matchers to be nested.  The idea is that
Port, if used, nests either Host, Location, or both, and Host nests Location.  I could throw an error, I suppose,
if Host were to nest Port, but I'll have to think about that.  That's one of those simple "which way is up?" questions
that I can never really get a handle on, being a fundamentally disoriented sort of person.  So scoping in a config 
file now could look like this:

Scope(Port(8888, 
           Host('www.skunk.org', 
                Location("test/foo", 
                         basicAuthFile="FooAuth", 
                         basicAuthName="Foo"))))

which, I think, is pretty reasonable, and if we were to move to XML config files or something similar,
we could make the translation very easily.  Note that a Scope directive is always needed; a Location 
by itself won't do anything (will just create a matcher object).


Wed May  2 17:07:43 2001

Hey, it actually seems to work, after a bit of tweaking.  I wouldn't be surprised if there are more bugs, however;
quite a bit of testing is in order.  Also, because of the tree-node-ish quality of the ScopeMatchers, some care has
to be taken in dealing with them.  In tests, I experienced weird persistence of objects that were supposed to go
out of scope, because of (inadvertent) mutual references.  

I'm dealing with different ports simply by getting their number from the socket.

########################################################################

Thu May  3 11:36:03 2001

Today: more testing of scope directives.  An IP directive might be a good idea as well (JC's idea), in fact, the port 
directive should be replaced by something that includes ip and optionally port, as there is nothing to prevent SW from
having server sockets open on the same port on different ip addresses.  That change should be made today.

The next step is making jobname scopeable.  At present, it doesn't belong to a scopeable object.  Should I add a 
temporary variable to the Configuration object which can override the current jobName, or should I make the sessionDict
scopeable?  Probably the former, although I'm not sure to find an elegant way of doing that.  Perhaps Configuration's 
temporary variable should be a suffix that is added on to the base jobName.  Or perhaps the current way of specifying
jobs, for templating, for example, should be replaced by using scoping.  A ListenPorts variable could give the list
of ports where services will be added, and scoping can be used to determine the jobs they will perform.  

New Scope utility functions may need to be created by other services, but at present they will need to be added to 
a static list in SkunkWeb.KickStart.py, as the config files are read before the services are loaded, unless i could
use the eval of the config file to actually perform the load before the utility functions are referenced, say when
Scope is called.  (But that won't work, as it is possible, even convenient, to call the matcher-generating functions
before calling Scope.)  Well, a relatively minor limitation, and one that may go away if the config file format is 
altered.

I've added an IP directive, and removed any port from the host field of the connection object, so the matching used
in the Host directive is now strict.

Thu May  3 14:52:27 2001

I've added a crude sort of job configurability.  Now I need to sketch out how I want job configuration to work.

First of all, is there any sort of scoping I can undertake in the requestHandler?  Yes: ip and port.  I can then
derive the initial job from the scope information.

Example configuration:

ipScope=IP("127.0.0.1", Port(8080, job=jobs.TEMPLATING_JOB), Port(9886, job=jobs.REMOTE_JOB))
Scope(ipScope)

or say that templating was the only job to be performed; one could put at the top level: 

job=jobs.TEMPLATING_JOB

There is no "jobs" object at present, but I think I will create one and load it into the config file namespace.
Or perhaps just the job constants. 

Thu May  3 17:22:37 2001

I'm in the midst of an overhaul which is cleaning up a lot of the cruftiest bits of what I've done, confirming
that I'm moving in the right direction. 

There is no "jobs" module; instead, I've created a "constants" module in requestHandler, which stores job names
and various other garbage.  

Jobs are now determined by configuration scope, on the basis of ip and port (and possibly location and host, in
the web service).  

The actual web services were, strangely enough, being created in templating and remote, which correspond to jobs,
rather than in web and httpd, which have actual protocol implementations.  That will now go away.  Configuration
of ports will look like this:

AecgiListenPorts=['TCP:localhost:9887']
HttpdListenPorts=['TCP::8080']

To have an actual service run on the port that doesn't throw a critical error when someone connects, you have
to specify a job, either at the top level or inside Scope calls.

Thu May  3 18:33:28 2001

Constants are a bit of a problem.  I want to define constants I can use inside sw.conf, but I don't want to have
to import the services from within it to get at it.  If the services aren't imported, however, how can they define
the constants?  It would help if the services, rather than simply being listed, were actually imported as the file
was evaluated, but I can't make that change before dinner.  A Services directive may be the solution, which simply
does the import.  Might make reload simpler, too.

Thu May  3 18:47:19 2001

I'm in the process of making major changes, and don't know if they yet work, so can't check them in.  Hold your hats!
Status: strategy for constants needs to be determined; then can run a test.

Fri May  4 10:06:17 2001

Constants are not the only problem.  The trimming of the configuration has to be checked.  I have some major doubts 
about this implementation, more about which later, when I have got it to work, which is the first step.  I believe
that functionality it accomplishes is correct, but the technique (use of global configuration object) is faulty and
probably too expensive.  We'll see.

Aecgi and SWRemote protocols are actually the same, and can now be coalesced.  Remote service is determined by job.
The only difference between the protocols, their error handling, can be accomplished with a hook.  

Fri May  4 14:29:13 2001

Previous statement about aecgi and swremote being the same was WRONG.  Aecgi uses marshal; remote uses pickle.  Duh.

I have, for the time being, hard-coded service constants in SkunkWeb.constants.  I don't like that.  I see only two
solutions: load the services while reading the config file, or use a symbolic name to which meaning is only attached
later.  I could, for instance, use a constants object with a funny getattr hook -- it would have to do quite a song and
dance, however.  Another alternative would be for people to put the actual job strings in the file.  That would be a
really bad idea, as the job strings are not meant for human consumption.

A Service directive is probably the right thing, this go round.  The next go round, for next week, is to address my 
architectural concerns in a big way, probably getting rid of the configuration object as is currently exists, and making
SkunkWeb thread-capable.

I should probably rename "aecgi" to "apache".  

The last week (current time Fri May  4 15:13:06 2001) was not wasted, because we have a tangible prototype of the kind of 
configurability we want; still, I am depressed by the implementation.  

It would be a good idea to reuse the connection object rather than creating a new one every request, if the previous
one is still hanging around in the sessionDict.

Sat May  5 03:00:59 2001

I did a fresh install of SW3, and after I got the sw.conf file right it ran correctly.  I must update the sw.conf.in so
it works correctly out the box with sample documents (to which I will add some).  Also, the installer needs to handle
more services; I had to install them manually.  MySQLdb should also either be checked in configure or installed in pylibs.

########################################################################

Mon May  7 14:57:44 2001

I improved the configure script, services makefile and default sw.conf so that it at least will run in a standard
configuration after a straightforward configure/make/make install.  

There are various things I could do next, some fun, some not so fun.  Some fun options that spring to mind are:
xmlrpc; remote debugging; an apache2 module; a DAV implementation; a cgi-wrapper (a cgi script that could be used instead 
of mod_skunkweb).  Remote debugging will probably involve xmlrpc, so I would imagine I would first want to do a remote
xmlrpc component service.

Less fun things: sessionHandler should be robustified in various ways -- tt should be able to use other rdbmses, as well
as oodbmses, shelve objects, etc., and distributed sessions, failover, should be looked into.  aed_compat and superteam
should be worked on, definitely (but I feel little enthusiasm at the moment).  I'll see if JC has time and is interested 
in using his AED expertise in this area. 

Mon May  7 16:15:17 2001

Rufus is now up and barking with SW3 and mod_dav.  

Mon May  7 19:13:50 2001

Spent much of the day mucking around with xml-rpc.  Quite a simple little toy; just a question of deciding how I want
SW to approach it.  Came across Winer's "cloud", a sort of object registry which communicates with XMLRPC.  Probably slow
as hell, but I rather like it.  Also various extensions to XML-RPC, not to the protocol itself, but special methods
a server can implement that do introspection, boxcarring of method calls, etc.  I'll add them, and since the way it would
probably work would involve many different servers (one for each URL in the XMLRPC-enabled area) I should probably go
further, and permit some way of searching a group of XML-RPC server components.  

########################################################################

Tue May  8 11:06:43 2001

XML-RPC/debugging day.  

Tue May  8 15:39:14 2001

First step, I think -- write a bdb subclass that permits the sort of control available in pdb, but 
delegates the i/o to an interface (which is where I will plug in xml-rpc or what have you).

########################################################################

Wed May  9 13:17:04 2001

I felt like fiddling with metaclasses this morning, thinking I could fix a minor bug in remote_client using
them.  This led to the realization that I didn't need a metaclass, I could just use exec and eval.  Some
namespace-diddling was required, but I can use it to dynamically create a mixin instance. 

Wed May  9 14:35:13 2001

Back to the debugger, and xmlrpc.

We have an advantage here in not being multithreaded, in that the debugger will only affect
one process.  The debugger will use httpd, and debugging will have to turn off if the connection
goes down, as otherwise the process will be in a funky state.  The connection will also be
kept alive while the debugger is running. 

Basically, all I need xmlrpc to do is send method requests to an xmlrpc server that will debug
the requested piece of python code.  How does one specify what that code should be?  Should I
assume that we will only want to use this for templates and what have you?  Probably not;
I should be able to generalize it.  

First, in order to debug an AE.Component, I need to execute it in an environment in which
I have called sys.settrace.  Once having done so, I will be debugging everything that occurs
in the debugged process.  So I need two hooks -- one to call sys.settrace with my debugger
code, the other call it again with None, unconditionally, when the connection goes down.

To make that work I had to add an EndSession hook to requestHandler, which actually cleans
up the code, and was clearly needed.

xmlrpc: we need an xmlrpc component handler, in addition to whatever other ways we might want
to instantiate xmlrpc services, if any.  It should be possible to call a remote component by
swrpc, xmlrpc, soap, iiop.  Is this being anal about the back end (ugh)?

Wed May  9 15:48:02 2001

random thought -- add File pseudo-directive to ConfigAdditives.

########################################################################

Thu May 10 15:28:53 2001

debugger issues.  

The debugging process goes as follows:

A special debugging service is setup on a given port/location (or possibly in a range of locations on a given port:

Possibility 1: from the url the debugger is able to determine the component that is supposed to be debugged.
Possibility 2: the component to be debugged must be specified with a "run" command.
Possibility 3: both: it is possible to invoke the debugger without specifying a component, in which you can't do
   much, or you can specify it the component in the initial request.  Sounds preferable.
)

Joe connects and is (optionally but preferably) authenticated.  He is now in a command loop, where he has a range of 
debugger commands available: setting and unsetting breakpoints, examining values, run, etc.  

Except for the sys.settrace call in the BeginSession hook, everything involved in the component execution (or whatever)
is the same as normal.


Now, what happens to the final output of the component?  If it is sent to Joe on the same socket, how will Joe feed it 
to whatever client  application is supposed to get it?  Is that our problem?  Is there a way to send the xmlrpc
communications on a different socket?  Two sockets per process: one is doing regular web traffic, accepting requests;
the other is connecting as a *client* to the same ip that requested the page on the debug service httpd port.  

Joe connects.

Server accepts, identifies it as a debug job.

Server tries to connect to joe's debug server socket.

Joe accepts debug connection.

There are now two duplex connections between joe and the server -- one of them talking xml-rpc, one of them talking
something else (whatever else).

Well, that's a start, but it is somewhat backwards -- probably joe should connect to the xml-rpc server first, and
then be told where to connect for the secondary (debuggee) connection.  

If this works within requestHandler, it is purely accidental, but I think it might; the sessionDict can store the
secondary socket.  The only issue is getting hooks to operate for two jobs at once, debug and the target job.  
Debug may have to put in functions into KeyedHooks that call the same keyed hooks with different jobs!  Oy.

Or how about this client-side solution: only one socket.  Joe connects to the xml-rpc debug server, specifies what
sort of job he wants to debug, what parameters apply, what breakpoints, etc.  His debug client has the responsibility
of sorting out application io from debug io; if a browser is required, for instance, one is started, connected to a
local forwarding proxy.  This way it would be possible to debug a stateful application with one socket, but the 
client application would have to do some work.  Well, that would be just fine with me.

All the debugger traffic will have to be marked as such, perhaps with a unique instance id (I wonder if the debugger
could then debug itself without falling into recursive death?!).  The methodResponses would have to have them as well.
Problem -- we can't possibly make this work with arbitrary protocols on one socket, not in the current design -- not 
unless Joe can specify the protocol in the command loop, and we would then more or less tunnel a requestHandler
process inside the xml-rpc server's requestHandler loop.  Weird, and what would it prove?  In a sense you wouldn't be
debugging the same code you would otherwise run.  The two socket solution, awkward though it is, would isolate the
debugger from the debuggee to a greater extent.

The other alternative is the most straightforward -- just send output to the same socket and make no effort to distinguish it.
This means that you could look at the output, but not use it very easily, and it would be more or less impossible to
debug anything statefully interactive.

Until I make up my mind about this, what can I do?  Just get a debugger working with a commander interface.

########################################################################

Fri May 11 11:08:25 2001

Debugger has another large job to do: find resources to debug.  In this case, setting a resource
is rather involved.  The resource could be a python file which is on sys.path, or it could be a
template or component.  Although the latter are absolutely essential, I'm leaving them aside for
the moment, to get a simpler case working.

########################################################################

Mon May 14 15:20:13 2001

unwell and attempts to write code went not too far.

########################################################################

Tue May 15 17:48:05 2001

Today I went in a different direction, still without much success.  Find it difficult to solve simple
problems, due to tiredness.  Tomorrow will probably go better.

########################################################################

Wed May 16 10:42:47 2001

Today I must make some progress.  Problems/issues: 

I've attempted to rewrite pdb so that it's interaction with the user goes through
an interface that handles communication.  I didn't do it well, for psychological 
reasons.  Then, thinking I might save myself some trouble and perhaps it was a better
idea anyway, I tried wrapping pdb, capturing its input and output, and redirecting that
through a socket.  Ran into IO troubles which I didn't entirely solve, although
I saw some intermittent functionality.  Part of the difficulty is that pdb is not
written to be componentized.  I am changing the behavior of readline(), for instance,
so that it reads an entire request.  I also tried switching from sending xmlrpc 
to sending length+string (but that wouldn't work through proxies, should stick with
an HTTP-based message, whether or not its xmlrpc).

I think I might send a special mime-type, x/application-skunk-debug or some such.  I can 
then mix debug messages and other output in the same stream and disambiguate them easily.

Today I want to start OVER again.  I will not wrap pdb, but will go with my earlier
approach of writing a Bdb subclass.  However, rather than try to lard it with the full
complement of debug commands sported by pdb, I will give it a very spartan command set
until I see it working in its intended environment.  

1. First, just a remote debugger that connects a python interpreter with a command-line 
   client.  
2. Then, integration of that debugger into a requestHandler loop.  Ability to specify
   something to debug.
3. More debug commands.
4. Template debugging.
5. Graphical client.

Wed May 16 13:53:19 2001

Out of an unhealthy compulsion, I spent some hours working on taking a cmd.Cmd and wrapping
it, which is what I said I wasn't going to do.  Got it to work to a very limited degree, 
but the i/o that a command line program does not consist of a neat series of exchanges, 
even if it could or should, and pdb tended to barf rather unpleasantly.  Chalking it up
to experience, I move on, grimly.

########################################################################

Thu May 17 14:08:36 2001

Some progress.  The client and server now talk to one another without getting completely lost.
However, this is presently at the cost of having the interaction function never return, which
is not very useful!  The socket stuff is very suspicious to me -- I doubt I've coded it the 
best way -- but it seems to work at present.  

Thu May 17 19:23:27 2001

The client and server are now functioning better, and a number of debug methods are implemented --
but I'll be damned if I can step through anything.  My breakpoints are getting ignored, for
reasons I have yet to figure out.

########################################################################
# $Log: NOTES,v $
# Revision 1.1  2001/08/05 14:58:04  drew_csillag
# Initial revision
#
# Revision 1.34  2001/07/06 18:39:25  drew
# added bit about mxDateTime
#
# Revision 1.33  2001/05/17 23:25:32  smullyan
# updates to diary
#
# Revision 1.32  2001/05/10 15:36:48  smullyan
# modified.
#
# Revision 1.31  2001/05/05 07:08:04  smullyan
# fresh SW install for verification.
#
# Revision 1.30  2001/05/04 20:04:40  smullyan
# fix: sessionHandler needed to use SkunkWeb.constants;
# fix: web.protocol (which no longer has a protocol in it, oy!) now
# cleans up a little more carefully and no longer deletes the connection
# object from sessionDict (I may recycle it)
#
# Revision 1.29  2001/05/04 18:38:46  smullyan
# architectural overhaul, possibly a reductio ad absurdum of the current
# config overlay technique.
#
# Revision 1.28  2001/05/03 22:49:26  smullyan
# modified.
#
# Revision 1.27  2001/05/03 17:26:40  smullyan
# more scoping modifications (for IP)
#
# Revision 1.26  2001/05/03 16:14:57  smullyan
# modifications for scoping.
#
# Revision 1.25  2001/05/02 04:23:44  smullyan
# negative eureka experience on subway.
#
# Revision 1.24  2001/05/01 23:03:38  smullyan
# added support for name-based virtual hosts.
#
# Revision 1.23  2001/05/01 21:46:27  smullyan
# introduced the use of scope.Scopeable to replace the the ConfigLoader.Config
# object.
#
# Revision 1.22  2001/04/27 21:32:41  smullyan
# more babble.
#
# Revision 1.21  2001/04/27 14:11:15  smullyan
# musings about location.
#
# Revision 1.20  2001/04/26 19:07:43  smullyan
# added mention of DefaultLanguage to sw.conf.in.
#
# Revision 1.19  2001/04/25 20:40:59  smullyan
# modifications for aed_compat; removal of "experimental" services, now renamed
# without the "_experimental" suffix.
#
# Revision 1.18  2001/04/24 21:43:00  smullyan
# fixed bug in httpd.protocol (was accidentally removing line return after
# HTTP response line, producing weirdness).  Removed call of deprecated
# method of config object in remote.__init__.py; added list of configuration
# variables that need to be documented to sw.conf.in.
#
# Revision 1.17  2001/04/23 22:53:53  smullyan
# added support for keep-alive.  Fixed server name (I had left out "SkunkWeb"
# and only included the version).
#
# Revision 1.16  2001/04/23 21:44:28  smullyan
# support for "headersOnly" methods and response statuses in web_experimental;
# mod_skunkweb also now respects its headers_only flag.
#
# Revision 1.15  2001/04/23 20:17:15  smullyan
# removed SKUNKWEB_SERVER_VERSION, which I found was redundant; fixed typo in
# httpd/protocol; renamed "debugServices" configuration variable to
# "initialDebugServices".
#
# Revision 1.14  2001/04/23 18:52:53  smullyan
# basicauth repaired.
#
# Revision 1.13  2001/04/23 17:30:06  smullyan
# basic fixes to basic auth and httpd; added KeepAliveTimeout to requestHandler,
# using select().
#
# Revision 1.12  2001/04/23 04:55:42  smullyan
# cleaned up some older code to use the requestHandler framework; modified
# all hooks and Protocol methods to take a session dictionary argument;
# added script to find long lines to util.
#
# Revision 1.11  2001/04/20 21:49:51  smullyan
# first working version of http server, still more rough than diamond.
#
# Revision 1.10  2001/04/19 21:44:54  smullyan
# added some detail to sw.conf.in; added SKUNKWEB_SERVER_VERSION variable to
# SkunkWeb package; more preliminary work on httpd service.
#
# Revision 1.9  2001/04/18 22:46:24  smullyan
# first gropings towards a web server.
#
# Revision 1.8  2001/04/16 17:52:58  smullyan
# some long lines split; bug in Server.py fixed (reference to deleted
# Configuration module on reload); logging of multiline messages can now
# configurably have or not have a log stamp on every line.
#
# Revision 1.7  2001/04/13 04:25:17  smullyan
# late-night corrections.
#
# Revision 1.6  2001/04/12 22:05:31  smullyan
# added remote call capability to the STML component tag; some cosmetic changes.
#
# Revision 1.5  2001/04/11 21:23:28  smullyan
# removed some stderr print statements.
#
# Revision 1.4  2001/04/11 20:47:10  smullyan
# more modifications to the debugging system to facilitate runtime change of
# debug settings.  Segfault in mmint.c fixed (due to not incrementing a
# reference count in the coercion method).
#
# Revision 1.3  2001/04/10 22:48:25  smullyan
# some reorganization of the installation, affecting various
# makefiles/configure targets; modifications to debug system.
# There were numerous changes, and this is still quite unstable!
#
# Revision 1.2  2001/04/04 20:21:23  smullyan
# final musings of the afternoon before I go unpack my new PC
#
# Revision 1.1  2001/04/04 20:02:31  smullyan
# adding my dev diary file.
#
########################################################################
